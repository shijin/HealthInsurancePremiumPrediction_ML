{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e930a96b-f4fc-4b0a-8584-c248080598bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6026, 19)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Governance_Fairness.ipynb : CELL 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# 1) Load models\n",
    "model_young = joblib.load('artifacts/model_young.joblib')   # age ≤ 25 (LinearRegression)\n",
    "model_rest  = joblib.load('artifacts/model_rest.joblib')    # age > 25 (XGBRegressor)\n",
    "\n",
    "# 2) Load scaler bundles (each is a dict with {'scaler': transformer, 'cols_to_scale': [...]})\n",
    "bundle_young = joblib.load('artifacts/scaler_young.joblib')\n",
    "bundle_rest  = joblib.load('artifacts/scaler_rest.joblib')\n",
    "\n",
    "scaler_young = bundle_young['scaler']\n",
    "cols_scale_y = list(bundle_young['cols_to_scale'])\n",
    "\n",
    "scaler_rest  = bundle_rest['scaler']\n",
    "cols_scale_r = list(bundle_rest['cols_to_scale'])\n",
    "\n",
    "# 3) Load unified test set: must include ALL features you used + target 'premium'\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Basic checks\n",
    "assert 'age' in test_df.columns, \"test_data.csv must contain 'age' (for model routing).\"\n",
    "assert 'annual_premium_amount' in test_df.columns, \"test_data.csv must contain the target column 'annual_premium_amount'.\"\n",
    "\n",
    "# Show quick shape\n",
    "test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f416592e-0ead-4229-a815-6b8008f26de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows routed → young (<=25): 6026 | rest (>25): 0\n",
      "(6026, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>number_of_dependants</th>\n",
       "      <th>income_lakhs</th>\n",
       "      <th>insurance_plan</th>\n",
       "      <th>genetical_risk</th>\n",
       "      <th>normalized_risk_score</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>region_Northwest</th>\n",
       "      <th>region_Southeast</th>\n",
       "      <th>region_Southwest</th>\n",
       "      <th>...</th>\n",
       "      <th>bmi_category_Underweight</th>\n",
       "      <th>smoking_status_Occasional</th>\n",
       "      <th>smoking_status_Regular</th>\n",
       "      <th>employment_status_Salaried</th>\n",
       "      <th>employment_status_Self-Employed</th>\n",
       "      <th>annual_premium_amount</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>model_used</th>\n",
       "      <th>model_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5452</td>\n",
       "      <td>5452</td>\n",
       "      <td>1172.965391</td>\n",
       "      <td>Model B (≤25)</td>\n",
       "      <td>v1.0-LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9658</td>\n",
       "      <td>9658</td>\n",
       "      <td>2433.214053</td>\n",
       "      <td>Model B (≤25)</td>\n",
       "      <td>v1.0-LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6031</td>\n",
       "      <td>6031</td>\n",
       "      <td>2250.253142</td>\n",
       "      <td>Model B (≤25)</td>\n",
       "      <td>v1.0-LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12386</td>\n",
       "      <td>12386</td>\n",
       "      <td>3933.896263</td>\n",
       "      <td>Model B (≤25)</td>\n",
       "      <td>v1.0-LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4245</td>\n",
       "      <td>4245</td>\n",
       "      <td>1213.435223</td>\n",
       "      <td>Model B (≤25)</td>\n",
       "      <td>v1.0-LR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  number_of_dependants  income_lakhs  insurance_plan  \\\n",
       "0  0.428571                   1.0      0.080808             0.0   \n",
       "1  0.714286                   0.0      0.030303             0.0   \n",
       "2  0.142857                   0.0      0.363636             0.0   \n",
       "3  0.428571                   0.0      0.515152             0.5   \n",
       "4  0.000000                   0.0      0.222222             0.0   \n",
       "\n",
       "   genetical_risk  normalized_risk_score  gender_Male  region_Northwest  \\\n",
       "0             0.2               0.428571            1                 0   \n",
       "1             0.8               1.000000            1                 0   \n",
       "2             0.0               1.000000            1                 0   \n",
       "3             0.8               0.428571            1                 0   \n",
       "4             0.0               0.000000            0                 0   \n",
       "\n",
       "   region_Southeast  region_Southwest  ...  bmi_category_Underweight  \\\n",
       "0                 0                 0  ...                         0   \n",
       "1                 0                 1  ...                         0   \n",
       "2                 0                 1  ...                         0   \n",
       "3                 1                 0  ...                         0   \n",
       "4                 1                 0  ...                         1   \n",
       "\n",
       "   smoking_status_Occasional  smoking_status_Regular  \\\n",
       "0                          0                       0   \n",
       "1                          0                       0   \n",
       "2                          0                       1   \n",
       "3                          0                       0   \n",
       "4                          0                       1   \n",
       "\n",
       "   employment_status_Salaried  employment_status_Self-Employed  \\\n",
       "0                           0                                0   \n",
       "1                           0                                0   \n",
       "2                           1                                0   \n",
       "3                           0                                0   \n",
       "4                           0                                0   \n",
       "\n",
       "   annual_premium_amount  y_true       y_pred     model_used  model_version  \n",
       "0                   5452    5452  1172.965391  Model B (≤25)        v1.0-LR  \n",
       "1                   9658    9658  2433.214053  Model B (≤25)        v1.0-LR  \n",
       "2                   6031    6031  2250.253142  Model B (≤25)        v1.0-LR  \n",
       "3                  12386   12386  3933.896263  Model B (≤25)        v1.0-LR  \n",
       "4                   4245    4245  1213.435223  Model B (≤25)        v1.0-LR  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Governance_Fairness.ipynb : CELL 2 (updated)\n",
    "\n",
    "# Use exact training-time feature order captured in the model artifacts\n",
    "feat_cols_young = list(getattr(model_young, 'feature_names_in_', []))\n",
    "feat_cols_rest  = [str(c) for c in getattr(model_rest,  'feature_names_in_', [])]  # cast np.str_ → str\n",
    "\n",
    "if not feat_cols_young or not feat_cols_rest:\n",
    "    raise ValueError(\"Models do not expose feature_names_in_. Save & load training column lists.\")\n",
    "\n",
    "# Check nothing missing for each segment\n",
    "missing_y = [c for c in feat_cols_young if c not in test_df.columns]\n",
    "missing_r = [c for c in feat_cols_rest  if c not in test_df.columns]\n",
    "if missing_y or missing_r:\n",
    "    raise ValueError(f\"Missing columns — YOUNG: {missing_y} | REST: {missing_r}\")\n",
    "\n",
    "# Routing masks\n",
    "mask_y = test_df['age'] <= 25\n",
    "mask_r = test_df['age'] > 25\n",
    "\n",
    "# Segment matrices in the exact trained order\n",
    "X_y = test_df.loc[mask_y, feat_cols_young].copy()\n",
    "X_r = test_df.loc[mask_r,  feat_cols_rest ].copy()\n",
    "\n",
    "def scale_with_expected(X_in: pd.DataFrame, scaler, cols_expected: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Safe scaling:\n",
    "      - If X_in is empty, return it unchanged (avoids MinMaxScaler error).\n",
    "      - Build a temp DF with the scaler's expected schema; fill any missing\n",
    "        expected cols with a neutral value (training stats if available, else 0).\n",
    "      - Transform, then write back scaled values only for overlapping cols.\n",
    "    \"\"\"\n",
    "    if X_in.shape[0] == 0:\n",
    "        return X_in  # <-- critical fix: no transform on empty input\n",
    "\n",
    "    X = X_in.copy()\n",
    "    original_cols = list(X.columns)\n",
    "\n",
    "    # temp DF with full expected schema\n",
    "    temp = pd.DataFrame(index=X.index)\n",
    "    for i, col in enumerate(cols_expected):\n",
    "        if col in X.columns:\n",
    "            temp[col] = X[col]\n",
    "        else:\n",
    "            # Neutral filler: try to use scaler stats; else 0.0\n",
    "            filler = 0.0\n",
    "            # StandardScaler: mean_\n",
    "            if hasattr(scaler, \"mean_\"):\n",
    "                filler = float(scaler.mean_[i])\n",
    "            # MinMaxScaler: data_min_ / data_max_ -> mid-point is neutral-ish\n",
    "            elif hasattr(scaler, \"data_min_\") and hasattr(scaler, \"data_max_\"):\n",
    "                mn = float(scaler.data_min_[i]); mx = float(scaler.data_max_[i])\n",
    "                filler = (mn + mx) / 2.0\n",
    "            temp[col] = filler\n",
    "\n",
    "    # transform with exact expected schema/order\n",
    "    Xt = scaler.transform(temp[cols_expected])\n",
    "    Xt = pd.DataFrame(Xt, index=temp.index, columns=cols_expected)\n",
    "\n",
    "    # write back only overlapping cols (preserve original order/set)\n",
    "    cols_to_write = [c for c in cols_expected if c in original_cols]\n",
    "    if cols_to_write:\n",
    "        X.loc[:, cols_to_write] = Xt[cols_to_write]\n",
    "\n",
    "    return X[original_cols]\n",
    "\n",
    "# Apply segment-specific scaling safely (now empty-safe)\n",
    "X_y_scaled = scale_with_expected(X_y, scaler_young, cols_scale_y)\n",
    "X_r_scaled = scale_with_expected(X_r, scaler_rest,  cols_scale_r)\n",
    "\n",
    "# Predict (already empty-safe)\n",
    "y_pred = pd.Series(index=test_df.index, dtype=float)\n",
    "if X_y_scaled.shape[0] > 0:\n",
    "    y_pred.loc[X_y_scaled.index] = model_young.predict(X_y_scaled)\n",
    "if X_r_scaled.shape[0] > 0:\n",
    "    y_pred.loc[X_r_scaled.index] = model_rest.predict(X_r_scaled)\n",
    "\n",
    "# Assemble df_predictions\n",
    "df_predictions = test_df.copy()\n",
    "df_predictions['y_true'] = df_predictions['annual_premium_amount']\n",
    "df_predictions['y_pred'] = y_pred\n",
    "df_predictions['model_used'] = np.where(mask_r, 'Model A (>25)', 'Model B (≤25)')\n",
    "df_predictions['model_version'] = df_predictions['model_used'].map({\n",
    "    'Model A (>25)': 'v1.0-XGB',\n",
    "    'Model B (≤25)': 'v1.0-LR'\n",
    "})\n",
    "\n",
    "print(\"Rows routed → young (<=25):\", X_y.shape[0], \"| rest (>25):\", X_r.shape[0])\n",
    "print(df_predictions.shape)\n",
    "df_predictions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ac62a89-16bb-48be-842c-9103778acff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rebuild categorical columns for fairness from one-hot columns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def onehot_to_label(df: pd.DataFrame, base: str, unknown_label: str = \"Unknown\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Collapse one-hot columns like base_* back into a single categorical label Series.\n",
    "    Example: base='smoking_status' -> looks for columns starting with 'smoking_status_'.\n",
    "    If a row has all zeros (or columns missing), returns 'Unknown'.\n",
    "    \"\"\"\n",
    "    cols = [c for c in df.columns if c.startswith(base + \"_\")]\n",
    "    if not cols:\n",
    "        # No one-hots present for this base\n",
    "        return pd.Series([unknown_label] * len(df), index=df.index, name=f\"{base}_grp\")\n",
    "\n",
    "    sub = df[cols].copy()\n",
    "\n",
    "    # Handle any non-binary due to float quirks by thresholding at 0.5\n",
    "    sub = (sub.values > 0.5).astype(int)\n",
    "    sub = pd.DataFrame(sub, index=df.index, columns=cols)\n",
    "\n",
    "    # Argmax to pick the active category per row\n",
    "    idx = sub.values.argmax(axis=1)\n",
    "    labels = [cols[i].replace(base + \"_\", \"\") for i in idx]\n",
    "\n",
    "    # If a row has no active one-hot (all zeros), mark Unknown\n",
    "    none_active = sub.sum(axis=1).values == 0\n",
    "    if none_active.any():\n",
    "        for i, na in enumerate(none_active):\n",
    "            if na:\n",
    "                labels[i] = unknown_label\n",
    "\n",
    "    return pd.Series(labels, index=df.index, name=f\"{base}_grp\")\n",
    "\n",
    "# Rebuild groups we want to audit\n",
    "df_fair = df_predictions.copy()\n",
    "\n",
    "# Gender, Smoking, BMI category, Region from one-hots\n",
    "df_fair['gender_grp']          = onehot_to_label(df_fair, 'gender')\n",
    "df_fair['smoking_status_grp']  = onehot_to_label(df_fair, 'smoking_status')\n",
    "df_fair['bmi_category_grp']    = onehot_to_label(df_fair, 'bmi_category')\n",
    "df_fair['region_grp']          = onehot_to_label(df_fair, 'region')\n",
    "\n",
    "# Income level: try one-hot first; if not present, derive from income_lakhs\n",
    "if any(col.startswith('income_level_') for col in df_fair.columns):\n",
    "    df_fair['income_level_grp'] = onehot_to_label(df_fair, 'income_level')\n",
    "else:\n",
    "    # Derive from income_lakhs into your four buckets: <10L, 10L - 25L, 25L - 40L, > 40L\n",
    "    def derive_income_level(x):\n",
    "        try:\n",
    "            v = float(x)\n",
    "        except Exception:\n",
    "            return \"Unknown\"\n",
    "        if v < 10:\n",
    "            return \"<10L\"\n",
    "        elif v < 25:\n",
    "            return \"10L - 25L\"\n",
    "        elif v < 40:\n",
    "            return \"25L - 40L\"\n",
    "        else:\n",
    "            return \"> 40L\"\n",
    "\n",
    "    if 'income_lakhs' in df_fair.columns:\n",
    "        df_fair['income_level_grp'] = df_fair['income_lakhs'].apply(derive_income_level)\n",
    "    else:\n",
    "        df_fair['income_level_grp'] = \"Unknown\"  # fallback\n",
    "\n",
    "# Optional: clean up common typos (e.g., Occassional → Occasional)\n",
    "def fix_label_typos(s: pd.Series) -> pd.Series:\n",
    "    mapping = {\n",
    "        \"Occassional\": \"Occasional\",  # common misspelling\n",
    "        \"Northwest \": \"Northwest\",    # stray spaces, if any\n",
    "        \"Southwest \": \"Southwest\",\n",
    "    }\n",
    "    return s.replace(mapping)\n",
    "\n",
    "df_fair['smoking_status_grp'] = fix_label_typos(df_fair['smoking_status_grp'])\n",
    "df_fair['region_grp']         = fix_label_typos(df_fair['region_grp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf890db0-1109-4624-9a06-d80c70c7aae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            count       MAE  Overcharge  Undercharge  Affordable_Pct  DIR  \\\n",
       " gender_grp                                                                  \n",
       " Unknown      2686  6187.583         0.0    -6187.583             0.0  0.0   \n",
       " Male         3340  6101.189         0.0    -6101.189             0.0  0.0   \n",
       " \n",
       "             MAE_vs_overall  \n",
       " gender_grp                  \n",
       " Unknown              0.008  \n",
       " Male                -0.006  ,\n",
       "                     count       MAE  Overcharge  Undercharge  Affordable_Pct  \\\n",
       " smoking_status_grp                                                             \n",
       " Unknown              4149  6147.945         0.0    -6147.945             0.0   \n",
       " Regular              1357  6139.435         0.0    -6139.435             0.0   \n",
       " Occasional            520  6074.581         0.0    -6074.581             0.0   \n",
       " \n",
       "                     DIR  MAE_vs_overall  \n",
       " smoking_status_grp                       \n",
       " Unknown             0.0           0.001  \n",
       " Regular             0.0          -0.000  \n",
       " Occasional          0.0          -0.011  )"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Fairness metrics on rebuilt group columns\n",
    "\n",
    "def fairness_metrics(df: pd.DataFrame, group_col: str, tolerance: float = 0.10):\n",
    "    \"\"\"\n",
    "    df must contain: y_true, y_pred, and group_col\n",
    "    tolerance = percentage window to count a prediction as 'affordable' (±10% default)\n",
    "    Returns: (metrics_df, overall_mae, overall_affordable_rate)\n",
    "    \"\"\"\n",
    "    use = df[['y_true','y_pred', group_col]].dropna().copy()\n",
    "    use['err'] = use['y_pred'] - use['y_true']\n",
    "    use['within_tol'] = (use['err'].abs() <= tolerance * use['y_true']).astype(int)\n",
    "\n",
    "    overall_mae = use['err'].abs().mean()\n",
    "    overall_aff = use['within_tol'].mean()\n",
    "\n",
    "    metrics = (use\n",
    "        .groupby(group_col, dropna=False)\n",
    "        .agg(\n",
    "            count=('y_true', 'size'),\n",
    "            MAE=('err', lambda x: x.abs().mean()),\n",
    "            Overcharge=('err', lambda x: np.maximum(x, 0).mean()),\n",
    "            Undercharge=('err', lambda x: np.minimum(x, 0).mean()),\n",
    "            Affordable_Pct=('within_tol', 'mean')\n",
    "        )\n",
    "        .assign(\n",
    "            DIR=lambda g: g['Affordable_Pct'] / (overall_aff if overall_aff > 0 else 1.0),\n",
    "            MAE_vs_overall=lambda g: (g['MAE'] - overall_mae) / (overall_mae if overall_mae > 0 else 1.0)\n",
    "        )\n",
    "        .sort_values('MAE', ascending=False)\n",
    "        .round(3)\n",
    "    )\n",
    "    return metrics, round(overall_mae, 3), round(overall_aff, 3)\n",
    "\n",
    "attributes_to_check = [\n",
    "    'gender_grp',\n",
    "    'smoking_status_grp',\n",
    "    'income_level_grp',\n",
    "    'bmi_category_grp',\n",
    "    'region_grp'\n",
    "]\n",
    "\n",
    "fairness_results = {attr: fairness_metrics(df_fair, attr) for attr in attributes_to_check}\n",
    "\n",
    "# Quick peeks\n",
    "fairness_results['gender_grp'][0], fairness_results['smoking_status_grp'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b5192-8f3c-43e2-9e0f-679127a8e172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
